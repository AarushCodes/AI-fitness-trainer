{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(landmarks):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for landmark in landmarks:\n",
    "    #if landmark.visibility >= 0.50:\n",
    "        x_values.append(landmark.x)\n",
    "        y_values.append(landmark.y)\n",
    "    \n",
    "    min_x = min(x_values)\n",
    "    min_y = min(y_values)\n",
    "    normalized_x  = [x - min_x for x in x_values]\n",
    "\n",
    "    normalized_y = [y- min_y for y in y_values]\n",
    "    #normalized_landmarks = list(zip(normalized_x, normalized_y))\n",
    "    normalized_landmarks = [item for pair in zip(normalized_x, normalized_y) for item in pair]\n",
    "    #print(normalized_landmarks)\n",
    "    return normalized_landmarks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            print(normalize_landmarks(landmarks))\n",
    "            \n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except:\n",
    "            #print(e)\n",
    "            pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def export_landmark(normalized_landmarks, action):\n",
    "    #print(type(normalized_landmarks))\n",
    "    # Check for None values in normalized_landmarks\n",
    "    if any(landmark is None for landmark in normalized_landmarks):\n",
    "        print('There are None values in normalized_landmarks.')\n",
    "        return\n",
    "\n",
    "    # Flatten the normalized_landmarks list\n",
    "    #flat_normalized_landmarks = [coord for landmark in normalized_landmarks for coord in landmark]\n",
    "\n",
    "    #print(len(flat_normalized_landmarks))\n",
    "    try:\n",
    "        # Insert the action at the beginning of the flattened list\n",
    "        #flat_normalized_landmarks.insert(0, action)\n",
    "        normalized_landmarks.insert(0,action)\n",
    "    except TypeError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Action: {action}\")\n",
    "        print(f\"Type of action: {type(action)}\")\n",
    "        print(f\"Normalized landmarks: {normalized_landmarks}\")\n",
    "        print(f\"Type of normalized landmarks: {type(normalized_landmarks)}\")\n",
    "        return\n",
    "\n",
    "    # Print the type of flat_normalized_landmarks\n",
    "    #print(type(flat_normalized_landmarks))\n",
    "\n",
    "    # Write the row to the CSV file\n",
    "    with open('try2squatswideornarrow.csv', mode='a', newline='') as f:\n",
    "        csvwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        #csvwriter.writerow(flat_normalized_landmarks)\n",
    "        csvwriter.writerow(normalized_landmarks)\n",
    "'''\n",
    "# Example usage\n",
    "normalized_landmarks_example = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]\n",
    "action_example = \"example_action\"\n",
    "export_landmark(normalized_landmarks_example, action_example)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKE NEW CSV FOR COORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "landmarks = ['class']\n",
    "for val in range (1,33+1):\n",
    "    landmarks += [f'x{val}',f'y{val}']\n",
    "print(landmarks)\n",
    "with open('try2squatswideornarrow.csv', mode='w', newline='') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csvwriter.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export landmarks for squats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exporting landmarks\n",
    "import csv\n",
    "def export_landmark(normalized_landmarks,action):\n",
    "    #print('started exporting')\n",
    "    if any(landmark is None for landmark in normalized_landmarks):\n",
    "        print('There are None values in normalized_landmarks.')\n",
    "        return\n",
    "    flat_normalized_landmarks = [coord for landmark in normalized_landmarks for coord in landmark]\n",
    "    print(type(flat_normalized_landmarks))\n",
    "    if None in flat_normalized_landmarks:\n",
    "        print('none values there')\n",
    "    row = flat_normalized_landmarks.insert(0,action)\n",
    "    with open('try2squatswideornarrow.csv', mode='a', newline='') as f:\n",
    "        csvwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csvwriter.writerow(row)\n",
    "    print('exported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code to export coordiantes based on keys pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('D:/python projects/ai cv/gym traniner/squatsv3.mp4')\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            #print(normalized_landmarks)\n",
    "            k =  cv2.waitKey(1)\n",
    "            if k == 117:\n",
    "                export_landmark(normalized_landmarks,'up')\n",
    "            if k == 100:\n",
    "                export_landmark(normalized_landmarks,'down')\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )\n",
    "            \n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #break\n",
    "            #pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train squats model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatcoords.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, 1:]  # Assuming the features start from column 1\n",
    "y = df['class']\n",
    "\n",
    "# Encode categorical labels ('up' and 'down') into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification, so using sigmoid activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Make Predictions\n",
    "predictions = model.predict(X_test)\n",
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test squats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('squatwideornarrow.h5')\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            testdata = np.array([normalized_landmarks])\n",
    "            predictions = model.predict(testdata)\n",
    "            #predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "            predicted_classes = np.argmax(predictions, axis=1)\n",
    "            predicted_classes_labels = label_encoder.inverse_transform(predicted_classes.flatten())\n",
    "            print(f'Predicted Class: {predicted_classes_labels}')\n",
    "            \n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    print('releasing')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training model to detect if squats are too wide or narrow \n",
    "### exporting landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_landmark_list(landmarks):\n",
    "     new_landmarks = []\n",
    "     for landmark in landmarks:\n",
    "          new_landmarks.append(landmark.x)\n",
    "          new_landmarks.append(landmark.y)\n",
    "     return new_landmarks\n",
    "cap = cv2.VideoCapture('squatslegswideornarrow.mp4')\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            #normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            #print(normalized_landmarks)\n",
    "            k =  cv2.waitKey(1)\n",
    "            if k == 111:\n",
    "                landmarks = make_landmark_list(landmarks)\n",
    "                export_landmark(landmarks,'perfect')\n",
    "            if k == 110 :\n",
    "                landmarks = make_landmark_list(landmarks)\n",
    "                export_landmark(landmarks,'narrow')\n",
    "            if k == 119 :\n",
    "                 landmarks = make_landmark_list(landmarks)\n",
    "                 export_landmark(landmarks,'wide')\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )\n",
    "            \n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #break\n",
    "            #pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatsv2narroworwide.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, 1:]  # Assuming the features start from column 1\n",
    "y = df['class']\n",
    "\n",
    "# Encode categorical labels ('up' and 'down') into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='softmax')  # softmax for multiple classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Make Predictions\n",
    "predictions = model.predict(X_test)\n",
    "#model.save('squatwideornarrow.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatswideornarrow.csv')\n",
    "\n",
    "# Keep only the desired columns (class, x32, y32, x33, y33)\n",
    "columns_to_keep = ['class', 'x32', 'y32', 'x33', 'y33']\n",
    "df_subset = df[columns_to_keep]\n",
    "\n",
    "# Save the subset to a new CSV file if needed\n",
    "df_subset.to_csv('squatsv2narroworwide.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatsv2narroworwide.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, 1:]  # Assuming the features start from column 1\n",
    "y = df['class']\n",
    "\n",
    "# Encode categorical labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert numerical labels to one-hot encoding\n",
    "y_one_hot = keras.utils.to_categorical(y_encoded, num_classes=3)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # Three classes, so using softmax activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train, epochs=64, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('squatwideornarrowv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('squatwideornarrow.h5')\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            #normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            normalized_landmarks = [value - landmarks[0] for i, value in enumerate(landmarks) if i not in [1, 3]]\n",
    "\n",
    "            testdata = np.array([normalized_landmarks])\n",
    "            #print(testdata)\n",
    "            predictions = model.predict(testdata)\n",
    "            #predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "            predicted_classes = np.argmax(predictions, axis=1)\n",
    "            predicted_classes_labels = label_encoder.inverse_transform(predicted_classes.flatten())\n",
    "            print(f'Predicted Class: {predicted_classes_labels}')\n",
    "            \n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    print('releasing')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatsv2narroworwide.csv')\n",
    "\n",
    "# Remove the 3rd and 5th columns\n",
    "df = df.drop(columns=[df.columns[2], df.columns[4]])\n",
    "\n",
    "# Subtract the 2nd column from itself and the 3rd column\n",
    "df[df.columns[1]] = df[df.columns[1]] - df[df.columns[1]]\n",
    "df[df.columns[2]] = df[df.columns[2]] - df[df.columns[1]]\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('squatsv3narroworwide.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('squatsv4wideornarrow.csv')  # Replace 'modified_file.csv' with the actual file path\n",
    "\n",
    "# Filter rows with specific classes ('perfect', 'wide', 'narrow')\n",
    "selected_classes = ['perfect', 'wide', 'narrow']\n",
    "df_filtered = df[df['class'].isin(selected_classes)]\n",
    "\n",
    "# Group by 'class' and find the lowest and highest values for each column\n",
    "result = df_filtered.groupby('class').agg({'x1': ['min', 'max'], 'x2': ['min', 'max']})\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('try2squatswideornarrow.csv')\n",
    "\n",
    "# Remove the 3rd and 5th columns\n",
    "#df = df.drop(columns=[df.columns[2], df.columns[4]])\n",
    "\n",
    "columns_to_keep = ['class', 'x30', 'x31', 'x32', 'x33']\n",
    "df_subset = df[columns_to_keep]\n",
    "df['legonedifference'] = df['x31'] - df['x33']\n",
    "df['legtwodifference'] = df['x32'] - df['x30']\n",
    "columns_to_keep = ['class', 'legonedifference', 'legtwodifference']\n",
    "df_subset = df[columns_to_keep]\n",
    "df_subset.to_csv('squatsv7wideornarrow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnarroworwide(feetlandmarks):\n",
    "    #feetlandmarks  = feetlandmarks[-4:]\n",
    "    legonedifference = feetlandmarks[1] - feetlandmarks[3]\n",
    "    legtwodifference = feetlandmarks[2] - feetlandmarks[0]\n",
    "    #print(legonedifference, ' ', legtwodifference)\n",
    "    if (legonedifference > -0.01 and legonedifference < 0.01) or (legtwodifference > -0.01 and legtwodifference < 0.01) :\n",
    "        status = 'perfect'\n",
    "    elif legonedifference > 0.01 or legtwodifference > 0.01:\n",
    "        status = 'wide'\n",
    "    elif legonedifference < -0.01 or legtwodifference < -0.01:\n",
    "        status = 'narrow'\n",
    "\n",
    "    else:\n",
    "        status = 'NA'\n",
    "    return status\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_legs_too_open_or_closed(landmarks):\n",
    "    diff1 = landmarks[30] - landmarks[12]\n",
    "    diff2 = landmarks[11] -  landmarks[29]\n",
    "    if (diff1 > -0.015 and diff1 < 0.015) or (diff2 > -0.015 and diff2 < 0.015):\n",
    "        status = 'perfect'\n",
    "    elif diff1< -0.015 or diff2< -0.015:\n",
    "        status = 'too open'\n",
    "    elif diff1 > 0.015 or diff2< 0.015:\n",
    "        status = 'too closed'\n",
    "    else:\n",
    "        status = 'NA'\n",
    "    \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted Class: down\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted Class: down\n",
      "releasing\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model2.h5')\n",
    "import numpy as np\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(['up', 'down'])\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, 480,640)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            testdata = np.array([normalized_landmarks])\n",
    "            predictions = model.predict(testdata)\n",
    "            predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "            #predicted_classes = np.argmax(predictions, axis=1)\n",
    "            predicted_classes_labels = label_encoder.inverse_transform(predicted_classes.flatten()).tolist()[0]\n",
    "            landmarks = [landmark.x for landmark in landmarks]\n",
    "            print(f'Predicted Class: {predicted_classes_labels}')  \n",
    "            #normalized_landmarks = normalize_landmarks(landmarks)\n",
    "            #print(isnarroworwide(landmarks[-4:]))\n",
    "            narroworwide = isnarroworwide(landmarks[-4:])\n",
    "            too_open_or_closed = are_legs_too_open_or_closed(landmarks)\n",
    "            # diff1 = landmarks[30] - landmarks[12]\n",
    "            # diff2 = landmarks[11] -  landmarks[29] \n",
    "            #print(diff1, 'second: ', diff2)\n",
    "            # cv2.putText(image, f'''second:{diff2}''',(50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f'norw: {narroworwide}, oc: {too_open_or_closed}, pos:{predicted_classes_labels}',(50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            #print(image.shape)\n",
    "            #print(topandbottom(landmarks))\n",
    "            #topandbottom(landmarks,resolution)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            #pass\n",
    "        \n",
    "        #print(landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
    "          \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    print('releasing')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
